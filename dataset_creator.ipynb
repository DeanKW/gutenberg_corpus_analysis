{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d1b43a4-9178-42e3-b1f4-efae28df9c70",
   "metadata": {},
   "source": [
    "This notebook will compare the metadata files created by the SPGC and the pg_catalog.csv from project gutenberg\n",
    "Then, it will make a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f715e7a-181d-4a8f-8150-6bf449cf0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import glob\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import misc_utils.dataset_filtering as dataset_filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c18e3-a6dd-4ea8-b154-cc0edf7a7a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_repo_path = '/Users/dean/Documents/gitRepos'\n",
    "gutenberg_repo_path = os.path.join(git_repo_path, 'gutenberg')\n",
    "gutenberg_analysis_repo = os.path.join(git_repo_path, 'gutenberg-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80022b-8e3e-47e0-a6b9-d3f8de15e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import internal helper functions\n",
    "analysis_src_dir = os.path.join(gutenberg_analysis_repo,'src')\n",
    "sys.path.append(analysis_src_dir)\n",
    "from data_io import get_book\n",
    "\n",
    "gutenberg_src_dir = os.path.join(gutenberg_repo_path,'src')\n",
    "sys.path.append(gutenberg_src_dir)\n",
    "\n",
    "from metaquery import meta_query\n",
    "from jsd import jsdalpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9e634-18a3-479b-be8b-bbb893c36841",
   "metadata": {},
   "source": [
    "# Read in both metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c90fc3-ae43-4692-87b7-3fe99ef2d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "mq_filepath=os.path.join(gutenberg_repo_path,'metadata','metadata.csv')\n",
    "pg_catalog_filepath=os.path.join(git_repo_path, 'gutenberg_corpus_analysis', 'sample_dataset', 'pg_catalog.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68986c78-9f8b-4154-bfae-f8b1e0681a44",
   "metadata": {},
   "source": [
    "# Load both  metadata files\n",
    "\n",
    "Load both the metadata file generated by SPGC and the metadata file from PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1f013a-f967-47cb-a3d6-87f43325d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_filtering.read_metadata_and_catalog(mq_filepath, pg_catalog_filepath)\n",
    "original_shape=df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8733d6-71ad-427a-b95a-6002e5bae7a3",
   "metadata": {},
   "source": [
    "Get only English books, according to PG catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query('Language==\"en\"')\n",
    "df['Language'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e9ae1",
   "metadata": {},
   "source": [
    "Let's verify that the language column in both metadata files match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa758df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f2dac",
   "metadata": {},
   "source": [
    "Uh oh, it doesn't!  What book is this causing the problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('Language==\"en\" and language==\"[\\'ne\\']\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd4c777",
   "metadata": {},
   "source": [
    "Lets get rid of it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_drop = df.query('Language==\"en\" and language==\"[\\'ne\\']\"').index\n",
    "df.drop(index_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79cfd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying that everything is good\n",
    "print(df['Language'].unique())\n",
    "print(df['language'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01dda6-9bd9-4b4d-ba26-965541706dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original Shape: {original_shape}')\n",
    "print(f'Current Shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a477b242",
   "metadata": {},
   "source": [
    "# Lets get rid of anything missing a title or an author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = df[['title', 'title_pgc', 'author', 'Authors']]\n",
    "tdf[tdf.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac7151a",
   "metadata": {},
   "source": [
    "Well, it looks like most of these HAVE authors (or at least editors), it's just messed up in the metadata created by SPGC.  Let's just drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72960cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5444508",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = tdf[tdf.isnull().any(axis=1)].index\n",
    "df.loc[to_drop].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc17552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc744c28",
   "metadata": {},
   "source": [
    "# Lets see if titles match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831fde79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dont_match, attribute_errors = dataset_filtering.compare_columns(df, 'title', 'title_pgc', verbose=True)#['author']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a105438-c3bf-4035-923f-7f8fb3648ea3",
   "metadata": {},
   "source": [
    "Let's get rid of PG63765 and lets note that we should get rid of copyright renewals en masse.\n",
    "\n",
    "We can also ditch the duplicate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2744e-9e8c-46d6-a8cf-504c1a887b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['id']!='PG63765']\n",
    "df.drop('title_pgc', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b365cf39",
   "metadata": {},
   "source": [
    "# Verify Author Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867b54c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dont_match, attribute_errors = dataset_filtering.compare_columns(df, 'author', 'Authors')#['author']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533df2ae-80cc-4214-a068-ed49a2bce631",
   "metadata": {},
   "source": [
    "Note that there are actually a bunch that don't match properly, but it appears that it is mostly a formatting issue.  We can come back to it, if needed.  Leaving them here\n",
    "\n",
    "Lets ditch the duplicate authors column though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e73d2b4-b41e-4299-a1f5-998afe8c34ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Authors', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e444ea-c288-4335-b7b7-7f9743066ded",
   "metadata": {},
   "source": [
    "# Do IDs match?  They better!\n",
    "\n",
    "Note: This should be totally unnecessary since we joined on ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e738c2c-9484-4300-ab10-e9b12ee5140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numeric version of the 'id' column with the \"PG\" removed\n",
    "df['id_numeric'] = (\n",
    "    df['id']\n",
    "    .str.replace('PG', '')  # remove the literal \"PG\"\n",
    "    .astype(str)            # convert to integer\n",
    ")\n",
    "\n",
    "df['PG_ID'] = df['PG_ID'].astype(str)              # Convert numeric to string\n",
    "\n",
    "dont_match, attribute_errors = dataset_filtering.compare_columns(\n",
    "    df,\n",
    "    'id_numeric',\n",
    "    'PG_ID',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f816f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dont_match)\n",
    "print(attribute_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa0eec",
   "metadata": {},
   "source": [
    "No entries show up with unmatching id's. We can drop the placeholder id_numeric column. I keep the redundant PG_ID column here not knowing if it will be useful later to query the raw data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999cf9cc-1abf-4407-84c5-86f95e9835da",
   "metadata": {},
   "source": [
    "# Where do we stand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3c764-5993-4f60-a829-0cc5cb456b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866d11f-7a7f-4fc1-936d-35615f3e97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3833e2-fbbf-435d-9b75-0f6338ed3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdfc06f-9a78-463a-8620-800604a64cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#df['author'].value_counts().plot(ax=ax, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69dcc1-21dd-4200-be19-5240b4c8a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['author'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a516ab-7836-485c-834d-36edea9bdfc7",
   "metadata": {},
   "source": [
    "It will be difficult to categorize \"Various\", \"Anonymous\", or \"Unknown\" authors, let's ditch them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b1fae1-13d9-4d7d-a146-077c93563f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['author'].isin(['Various', 'Anonymous', 'Unknown'])]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705b13c3-f522-4f1e-bb4a-2dc6597b5f4c",
   "metadata": {},
   "source": [
    "Lets see how many authors have more than 10 or 20 books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26b05a-17f9-4ee1-ae32-81481ecdbdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = df['author'].value_counts()\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e8512-8197-4101-8297-dde8f4c9754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are a total of {len(vc)} authors')\n",
    "for book_count in [10, 20, 30, 40, 50, 75, 100]:\n",
    "    print(f'There are {len(vc[vc > book_count])} authors with more than {book_count} books')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007efcf8-49c4-457f-92ef-56a1358041e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What should be the minimum number of books per author?\n",
    "book_count_cutoff=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe34d2a-f7db-4b81-99da-909c0084b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_to_include = vc[vc > book_count_cutoff].index\n",
    "\n",
    "mask = df['author'].isin(authors_to_include)\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3293c-6cda-487e-9516-860518a29e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248cfcd8-81a5-483e-988d-a118fcbd8b1e",
   "metadata": {},
   "source": [
    "# Add information on the length of books\n",
    "\n",
    "Adds the number of lines, the number of words, and the number of unique words\n",
    "\n",
    "By default, drops the books you haven't downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2346cfc2",
   "metadata": {},
   "source": [
    "#### Add the total word count of the entry, called 'word_count'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9f3ab-a896-49da-9ce4-439024dccc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_count(book_id, raw_text_dir):\n",
    "    \"\"\"\n",
    "    Given something like 'PG10007' and a directory containing a file called\n",
    "    'PG10007_counts.txt' whose lines each have a word and a count, sum up\n",
    "    all those counts and return the total.\n",
    "    \"\"\"\n",
    "    filename = f\"{book_id}_counts.txt\"\n",
    "    file_path = os.path.join(raw_text_dir, filename)\n",
    "\n",
    "    # If the file doesn’t exist, return None\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "\n",
    "    total_count = 0\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # Each line looks like: word count\n",
    "            word, count_str = line.strip().split()\n",
    "            total_count += int(count_str)\n",
    "\n",
    "    return total_count\n",
    "\n",
    "raw_text_path = r\"C:/Users/Hunter Worssam/Data Science/Theory of ML/Group Project/gutenberg/data/counts\" \n",
    "df[\"word_count\"] = df[\"id\"].apply(lambda pid: get_word_count(pid, raw_text_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208eecb7",
   "metadata": {},
   "source": [
    "#### Add the total unique word count of the entry, called 'unique_word_count'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62cceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_word_count(book_id, raw_text_dir):\n",
    "    \"\"\"\n",
    "    Given something like 'PG10007' and a directory containing a file \n",
    "    called 'PG10007_counts.txt' whose lines each have 'word count',\n",
    "    return how many lines that file has (i.e., how many unique words).\n",
    "    \"\"\"\n",
    "    filename = f\"{book_id}_counts.txt\"\n",
    "    file_path = os.path.join(raw_text_dir, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "\n",
    "    # Count lines to get # of unique words\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        num_unique_words = sum(1 for _ in f)\n",
    "\n",
    "    return num_unique_words\n",
    "\n",
    "raw_text_path = r\"C:/Users/Hunter Worssam/Data Science/Theory of ML/Group Project/gutenberg/data/counts\"\n",
    "df[\"unique_word_count\"] = df[\"id\"].apply(\n",
    "    lambda pid: get_unique_word_count(pid, raw_text_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921728d4",
   "metadata": {},
   "source": [
    "#### Add total lines of text in the raw text file, called 'line_count'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8356fd-c9ef-4b9f-a853-063f9c0a0115",
   "metadata": {},
   "source": [
    "Note that this is taking line count of the somewhat-cleaned files in the text folder, not the files in the raw folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_count(book_id, text_dir):\n",
    "    \"\"\"\n",
    "    Given something like 'PG10007' and a directory containing\n",
    "    'PG10007_text.txt', return how many lines are in the file.\n",
    "    \"\"\"\n",
    "    filename = f\"{book_id}_text.txt\"  \n",
    "    file_path = os.path.join(text_dir, filename)\n",
    "\n",
    "    # If the file doesn’t exist, return None (or 0)\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "\n",
    "    # Count lines\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        line_count = sum(1 for _ in f)\n",
    "\n",
    "    return line_count\n",
    "\n",
    "raw_text_path = r\"C:/Users/Hunter Worssam/Data Science/Theory of ML/Group Project/gutenberg/data/text\"\n",
    "df[\"line_count\"] = df[\"id\"].apply(\n",
    "    lambda pid: get_line_count(pid, raw_text_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee70225",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "#### Add total tokens in the entry, called 'token_count'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_count(book_id, text_dir):\n",
    "    \"\"\"\n",
    "    Given something like 'PG10007' and a directory containing\n",
    "    'PG10007_tokens.txt', return how many lines are in the file.\n",
    "    \"\"\"\n",
    "    filename = f\"{book_id}_tokens.txt\"  \n",
    "    file_path = os.path.join(text_dir, filename)\n",
    "\n",
    "    # If the file doesn’t exist, return None (or 0)\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "\n",
    "    # Count lines\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        token_count = sum(1 for _ in f)\n",
    "\n",
    "    return token_count\n",
    "\n",
    "raw_text_path = r\"C:/Users/Hunter Worssam/Data Science/Theory of ML/Group Project/gutenberg/data/tokens\"\n",
    "df[\"token_count\"] = df[\"id\"].apply(\n",
    "    lambda pid: get_token_count(pid, raw_text_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1625351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af122c-9329-41b2-a93f-6dbd3ef947e2",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7814b74-7f45-4fe3-8e52-479d76ce8bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be605ac2-86f3-4041-ac90-168ecd1f01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#####################\n",
    "def normalize_dataset(df, how='num_books'):\n",
    "    author_list = df['author'].unique()\n",
    "    vc = df['author'].value_counts()\n",
    "\n",
    "    min_num_books = vc.min()\n",
    "\n",
    "    for author in author_list:\n",
    "        tdf = df.query('author==@author')\n",
    "        num_to_drop = tdf.shape[0] - min_num_books\n",
    "        ind_to_drop = tdf.sample(num_to_drop).index\n",
    "        df.drop(ind_to_drop, inplace=True)\n",
    "    \n",
    "def split_test_train(df, train_perc=0.8):\n",
    "    author_list = df['author'].unique()\n",
    "    train_ind = []\n",
    "    for author in author_list:\n",
    "        tdf = df.query('author==@author')\n",
    "        single_author_train_ind = tdf.sample(frac=train_perc).index\n",
    "        train_ind = [*train_ind,*single_author_train_ind]\n",
    "\n",
    "    train_df = df.loc[train_ind]\n",
    "    test_df = df.drop(train_ind)\n",
    "\n",
    "    return train_df, test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf7fca-0898-4cfb-9ac7-1aab8bc762a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb3aed-519c-4e42-aa6e-33e28704d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b87583-c105-4970-acf4-ccc4021b25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_test_train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76324f82-ef4d-486e-960a-cd7fe6cefdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8d0e2-fb5f-4600-9d96-706b8eb5e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d5ffa-a6fc-4b5c-9fa0-5cf491c2801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv_in_metadata_format(df, outfile):\n",
    "    cols_to_keep = ['id', 'title', 'author', 'authoryearofbirth', 'authoryearofdeath',\n",
    "       'language', 'downloads', 'subjects']\n",
    "    df = df[cols_to_keep]\n",
    "    df.to_csv(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ae5f4-7eae-4387-befb-c8884b943d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outfile = 'train.csv'\n",
    "test_outfile = 'test.csv'\n",
    "write_csv_in_metadata_format(train_df, train_outfile)\n",
    "write_csv_in_metadata_format(test_df, test_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4e10d-e29f-4a36-83be-a546911e8d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "school-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
