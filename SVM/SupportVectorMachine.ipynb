{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "32fbcf73-c7e7-4bf8-a071-b2ee482d6114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "import io\n",
    "import os.path\n",
    "import re\n",
    "import tarfile\n",
    "import sys\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk import pos_tag\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a60d3b-0528-4731-89be-e94847447ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f96fa074-d4b2-4e83-ba36-0a5298ba51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "\n",
    "gutenberg_corpus_analysis_repo = os.path.join(repos_path, 'gutenberg_corpus_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d000760-41df-41e0-8b7e-88e35178d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gutenberg_repo_path = os.path.join(repos_path, 'gutenberg')\n",
    "gutenberg_analysis_repo = os.path.join(repos_path, 'gutenberg-analysis')\n",
    "\n",
    "src_dir = os.path.join(gutenberg_analysis_repo,'src')\n",
    "sys.path.append(src_dir)\n",
    "from data_io import get_book\n",
    "\n",
    "\n",
    "gutenberg_src_dir = os.path.join(gutenberg_repo_path,'src')\n",
    "sys.path.append(gutenberg_src_dir)\n",
    "\n",
    "from metaquery import meta_query\n",
    "\n",
    "sys.path.append(gutenberg_corpus_analysis_repo)\n",
    "import misc_utils.dataset_filtering as dataset_filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb9aa694-08ee-4f45-92de-2721335af46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_fold=os.path.join(gutenberg_repo_path, 'data', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c3655ce-665a-4581-a96a-a7d629b0d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='nikita_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e80954b-c2c0-401d-8271-d0a96214f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = os.path.join(gutenberg_corpus_analysis_repo, dataset, 'final_train.csv')\n",
    "test_csv = os.path.join(gutenberg_corpus_analysis_repo, dataset, 'final_test.csv')\n",
    "val_csv = os.path.join(gutenberg_corpus_analysis_repo, dataset, 'final_val.csv')\n",
    "\n",
    "pg_catalog_filepath=os.path.join(gutenberg_repo_path, 'metadata', 'pg_catalog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eebe32a1-6966-478a-94d7-b8175e422c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1eb0c18-5463-45bd-b273-4436ae623067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>authoryearofbirth</th>\n",
       "      <th>authoryearofdeath</th>\n",
       "      <th>language</th>\n",
       "      <th>downloads</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>PG12810</td>\n",
       "      <td>Uncle Sam's Boys with Pershing's Troops: Or, D...</td>\n",
       "      <td>Hancock, H. Irving (Harrie Irving)</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>78</td>\n",
       "      <td>{'World War, 1914-1918 -- Juvenile fiction', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>PG12819</td>\n",
       "      <td>Dick Prescott's Second Year at West Point: Or,...</td>\n",
       "      <td>Hancock, H. Irving (Harrie Irving)</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>94</td>\n",
       "      <td>{'United States Military Academy -- Juvenile f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25920</th>\n",
       "      <td>PG40605</td>\n",
       "      <td>The Motor Boat Club at Nantucket; or, The Myst...</td>\n",
       "      <td>Hancock, H. Irving (Harrie Irving)</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>189</td>\n",
       "      <td>{'Motorboats -- Juvenile fiction', 'Nantucket ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55435</th>\n",
       "      <td>PG8153</td>\n",
       "      <td>The Young Engineers in Arizona; or, Laying Tra...</td>\n",
       "      <td>Hancock, H. Irving (Harrie Irving)</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>190</td>\n",
       "      <td>{'Civil engineers -- Fiction', 'Arizona -- Fic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32899</th>\n",
       "      <td>PG48863</td>\n",
       "      <td>The Motor Boat Club off Long Island; or, A Dar...</td>\n",
       "      <td>Hancock, H. Irving (Harrie Irving)</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>85</td>\n",
       "      <td>{'Motorboats -- Juvenile fiction', 'Long Islan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "2439   PG12810  Uncle Sam's Boys with Pershing's Troops: Or, D...   \n",
       "2446   PG12819  Dick Prescott's Second Year at West Point: Or,...   \n",
       "25920  PG40605  The Motor Boat Club at Nantucket; or, The Myst...   \n",
       "55435   PG8153  The Young Engineers in Arizona; or, Laying Tra...   \n",
       "32899  PG48863  The Motor Boat Club off Long Island; or, A Dar...   \n",
       "\n",
       "                                   author  authoryearofbirth  \\\n",
       "2439   Hancock, H. Irving (Harrie Irving)             1868.0   \n",
       "2446   Hancock, H. Irving (Harrie Irving)             1868.0   \n",
       "25920  Hancock, H. Irving (Harrie Irving)             1868.0   \n",
       "55435  Hancock, H. Irving (Harrie Irving)             1868.0   \n",
       "32899  Hancock, H. Irving (Harrie Irving)             1868.0   \n",
       "\n",
       "       authoryearofdeath language  downloads  \\\n",
       "2439              1922.0   ['en']         78   \n",
       "2446              1922.0   ['en']         94   \n",
       "25920             1922.0   ['en']        189   \n",
       "55435             1922.0   ['en']        190   \n",
       "32899             1922.0   ['en']         85   \n",
       "\n",
       "                                                subjects  \n",
       "2439   {'World War, 1914-1918 -- Juvenile fiction', '...  \n",
       "2446   {'United States Military Academy -- Juvenile f...  \n",
       "25920  {'Motorboats -- Juvenile fiction', 'Nantucket ...  \n",
       "55435  {'Civil engineers -- Fiction', 'Arizona -- Fic...  \n",
       "32899  {'Motorboats -- Juvenile fiction', 'Long Islan...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_csv, index_col='Unnamed: 0')\n",
    "test_df = pd.read_csv(test_csv, index_col='Unnamed: 0')\n",
    "val_df = pd.read_csv(val_csv, index_col='Unnamed: 0')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57318e71-dc3c-4978-89a7-85387744bc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['author'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "064962ec-eb85-40b9-bf7b-492665c54a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = train_df['subjects'].replace('set()',np.nan)\n",
    "subj_docs = []\n",
    "for h in subj:\n",
    "    try:\n",
    "        h = h.strip(\"{}\")[1:-1]\n",
    "    except AttributeError:\n",
    "        subj_docs.append(h)\n",
    "        continue\n",
    "    h = h.replace(' -- ', '-')\n",
    "    h = h.replace(\"', '\",\"_\")\n",
    "    h = h.split('_')\n",
    "    h = [item.replace(' ','').replace(',', ' ') for item in h]\n",
    "    h = ' '.join(h)\n",
    "    subj_docs.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f13d40b-fb10-4122-9503-3fdd0d49d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['subj_str']=subj_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ae85678-cbde-4f72-aa04-aa18687c7b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df['subject_str'] = train_df['subjects'].apply(lambda x: split_subjects(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bab03ba0-50a4-4263-b70b-1e450df7746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = train_df.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3da0a2f0-29d6-4991-8432-05c24d333203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 5.5778257846832275 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_df['text'] = train_df['id'].apply(lambda x: get_book(x, path_gutenberg=gutenberg_repo_path,level='text'))\n",
    "test_df['text'] = test_df['id'].apply(lambda x: get_book(x, path_gutenberg=gutenberg_repo_path,level='text'))\n",
    "val_df['text'] = val_df['id'].apply(lambda x: get_book(x, path_gutenberg=gutenberg_repo_path,level='text'))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time elapsed: {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31a62839-5800-480c-9448-b157e495c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_start_and_end(text):\n",
    "    text = text.split(' ')\n",
    "    text = text[50:-50]\n",
    "    return ' '.join(text)\n",
    "\n",
    "train_df['text'] = train_df['text'].apply(skip_start_and_end)\n",
    "test_df['text'] = test_df['text'].apply(skip_start_and_end)\n",
    "val_df['text'] = val_df['text'].apply(skip_start_and_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "def85af7-de98-44b6-8183-71c55a8996c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_chunks(text, num_chunks=10, chunk_size=1000, overlap=False):\n",
    "    chunk = []\n",
    "    words = text.split(' ')\n",
    "\n",
    "    if num_chunks * chunk_size > len(words):\n",
    "        return text\n",
    "    for i in range(num_chunks):\n",
    "        new_words = []\n",
    "        num_words = len(words)\n",
    "        if chunk_size > num_words:\n",
    "            chunk = chunk + words\n",
    "            words = []\n",
    "            return ' '.join(chunk)\n",
    "        start = random.randint(0, num_words)\n",
    "        chunk = [*chunk,  *words[start:start+chunk_size]]\n",
    "        #print(chunk)\n",
    "        if start == 0:\n",
    "            words = words[chunk_size:]\n",
    "        elif start == num_words - chunk_size:\n",
    "            words = words[0:start]\n",
    "        else:\n",
    "            words = words[0:start] + words[start+chunk_size:]\n",
    "    return ' '.join(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6d6c419-fb8d-4aaf-80a6-a1905fc19f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['chunks'] = train_df['text'].apply(lambda x: make_random_chunks(x, num_chunks=10, chunk_size = 1000, overlap=False))\n",
    "test_df['chunks'] = test_df['text'].apply(lambda x: make_random_chunks(x, num_chunks=10, chunk_size = 1000, overlap=False))\n",
    "val_df['chunks'] = val_df['text'].apply(lambda x: make_random_chunks(x, num_chunks=10, chunk_size = 1000, overlap=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d3a0452-7502-4ee8-ac66-8abab76c420b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 12.205879211425781 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with mp.Pool(11) as pool:\n",
    "    train_df['tokenized'] = pool.map(word_tokenize, train_df['chunks'])\n",
    "end = time.time()\n",
    "print(f'Took {end-start} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8747fa30-c79a-4445-b89f-3bdad5d72ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 3.855489492416382 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "start = time.time()\n",
    "with mp.Pool(11) as pool:\n",
    "    val_df['tokenized'] = pool.map(word_tokenize, val_df['chunks'])\n",
    "end = time.time()\n",
    "print(f'Took {end-start} seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee8b788e-bad3-4a35-8958-45de059976b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4.1067750453948975 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "start = time.time()\n",
    "with mp.Pool(11) as pool:\n",
    "    test_df['tokenized'] = pool.map(word_tokenize, test_df['chunks'])\n",
    "end = time.time()\n",
    "print(f'Took {end-start} seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "095b07d6-4101-47ae-bf35-78f4afd85645",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile=os.path.join(gutenberg_corpus_analysis_repo, 'tokenized', 'train_df_chunks_tokenized.pkl')\n",
    "train_df.to_pickle(outfile)\n",
    "\n",
    "outfile=os.path.join(gutenberg_corpus_analysis_repo, 'tokenized', 'val_df_chunks_tokenized.pkl')\n",
    "val_df.to_pickle(outfile)\n",
    "\n",
    "outfile=os.path.join(gutenberg_corpus_analysis_repo, 'tokenized', 'test_df_chunks_tokenized.pkl')\n",
    "test_df.to_pickle(outfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8d0c4a0-7ea1-4336-bc3f-1eb2eef98be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0bb95786-4686-49f4-987c-3ba5f033ea18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>authoryearofbirth</th>\n",
       "      <th>authoryearofdeath</th>\n",
       "      <th>language</th>\n",
       "      <th>downloads</th>\n",
       "      <th>subjects</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0.1, id, title, author, authoryearofbirth, authoryearofdeath, language, downloads, subjects, text, chunks, tokenized]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['tokenized'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5754768-e015-4dd4-9cad-edf72f6e8c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>authoryearofbirth</th>\n",
       "      <th>authoryearofdeath</th>\n",
       "      <th>language</th>\n",
       "      <th>downloads</th>\n",
       "      <th>subjects</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0.1, id, title, author, authoryearofbirth, authoryearofdeath, language, downloads, subjects, text, chunks, tokenized]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['tokenized'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c735553-42b1-4b6b-826c-08e16c6612cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>authoryearofbirth</th>\n",
       "      <th>authoryearofdeath</th>\n",
       "      <th>language</th>\n",
       "      <th>downloads</th>\n",
       "      <th>subjects</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0.1, id, title, author, authoryearofbirth, authoryearofdeath, language, downloads, subjects, text, chunks, tokenized]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[val_df['tokenized'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2795859-7ed7-4d9f-aa64-d2aab1f0af8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Doyle, Arthur Conan', 'Shakespeare, William', 'Bennett, Arnold',\n",
       "       'Library of Congress. Copyright Office',\n",
       "       'Haggard, H. Rider (Henry Rider)', 'Roosevelt, Theodore',\n",
       "       'Jacobs, W. W. (William Wymark)', 'Howells, William Dean',\n",
       "       'Hancock, H. Irving (Harrie Irving)', 'Stratemeyer, Edward',\n",
       "       'Garis, Howard Roger', 'Balzac, Honoré de',\n",
       "       'Chesterton, G. K. (Gilbert Keith)', 'Dumas, Alexandre',\n",
       "       'Tolstoy, Leo, graf', 'Sinclair, Upton', 'Stevenson, Robert Louis',\n",
       "       'Bower, B. M.', 'Wells, Carolyn', 'MacDonald, George',\n",
       "       'Verne, Jules', 'Scott, Walter', 'London, Jack',\n",
       "       'Wells, H. G. (Herbert George)', 'Davis, Richard Harding',\n",
       "       'Kipling, Rudyard', 'James, Henry', 'Wharton, Edith',\n",
       "       'Harte, Bret', 'Yonge, Charlotte M. (Charlotte Mary)',\n",
       "       'Ellis, Edward Sylvester', 'Hawthorne, Nathaniel',\n",
       "       'Garrett, Randall', 'Lang, Andrew', 'Twain, Mark',\n",
       "       'Lever, Charles James', 'Trollope, Anthony',\n",
       "       'Goldfrap, John Henry', 'Hoare, Edward', 'Aimard, Gustave',\n",
       "       'Le Queux, William', 'Dickens, Charles',\n",
       "       'Benson, E. F. (Edward Frederic)', 'Meade, L. T.',\n",
       "       'Braddon, M. E. (Mary Elizabeth)', 'Snell, Roy J. (Roy Judson)',\n",
       "       'Leinster, Murray', 'Harper, Charles G. (Charles George)',\n",
       "       'Baring-Gould, S. (Sabine)', 'Russell, William Clark',\n",
       "       'Meredith, George', 'Barbour, Ralph Henry', 'Matthews, Stanley R.',\n",
       "       'Henty, G. A. (George Alfred)',\n",
       "       'United States. National Park Service', 'Conrad, Joseph',\n",
       "       'Cannon, Richard', 'James, G. P. R. (George Payne Rainsford)',\n",
       "       'A. L. O. E.', 'Westerman, Percy F. (Percy Francis)',\n",
       "       'Castlemon, Harry', 'Oliphant, Mrs. (Margaret)',\n",
       "       'Baum, L. Frank (Lyman Frank)', 'Alger, Horatio, Jr.',\n",
       "       'Hume, Fergus', 'Miller, Alex. McVeigh, Mrs.', 'Zola, Émile',\n",
       "       'Belloc, Hilaire', 'Bond, Nelson S.', 'Parker, Gilbert',\n",
       "       'Grant, James', 'Carter, Nicholas (House name)',\n",
       "       'Standish, Burt L.', 'Marlowe, Stephen',\n",
       "       'Tuttle, W. C. (Wilbur C.)', 'Smith, George O. (George Oliver)',\n",
       "       'Holmes, Mary Jane', 'Burroughs, Edgar Rice',\n",
       "       'Blanchard, Amy Ella', 'Lytton, Edward Bulwer Lytton, Baron'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['author'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b727fad-3b10-48db-aef3-02173eb4b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03026a4a-dd24-4f93-bbdc-165219447a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(tokenized_text):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(tokenized_text):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_final = word_lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            final_words.append(word_final)\n",
    "    return str(final_words)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2113b336-d875-4362-8432-f715578960d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 37.59381318092346 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with mp.Pool(11) as pool:\n",
    "    lemmatized = pool.map(lemmatize_text, train_df['tokenized'])\n",
    "end = time.time()\n",
    "print(f'Took {end-start} seconds')\n",
    "train_df['lemmatized'] = lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4fa10616-d82b-41ce-9025-637f9c7d3d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 37.27150344848633 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "start = time.time()\n",
    "with mp.Pool(11) as pool:\n",
    "    lemmatized = pool.map(lemmatize_text, val_df['tokenized'])\n",
    "end = time.time()\n",
    "print(f'Took {end-start} seconds')\n",
    "val_df['lemmatized'] = lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eccdb7d2-2c4b-48ea-9452-1e60d2095f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 37.826552391052246 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "start = time.time()\n",
    "with mp.Pool(11) as pool:\n",
    "    lemmatized = pool.map(lemmatize_text, test_df['tokenized'])\n",
    "end = time.time()\n",
    "print(f'Took {end-start} seconds')\n",
    "test_df['lemmatized'] = lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bd53cea7-6ccb-4cea-b25f-72f347e5cb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 13)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5da91f-56e4-418a-9d91-3663f3b95b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "909eb400-a0af-4765-a776-05ee5c1c324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Train_Y = train_df['lemmatized'], train_df['author']\n",
    "Test_X, Test_Y = test_df['lemmatized'], test_df['author']\n",
    "Val_X, Val_Y = val_df['lemmatized'], val_df['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba94d71-cf70-4eac-9f5f-91a43fcb3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_X, _, Train_Y, _ = model_selection.train_test_split(train_df['lemmatized'], train_df['author'],test_size=0.3)\n",
    "# Val_X, _, Val_Y, _ = model_selection.train_test_split(val_df['lemmatized'], val_df['author'],test_size=0.3)\n",
    "# Test_X, _, Test_Y, _ = model_selection.train_test_split(test_df['lemmatized'], test_df['author'],test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed26a1-cdfd-49f3-a059-3508fc3037d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "444b2c5d-5a8a-4d1a-a186-bf9bdc8c518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y_e = Encoder.fit_transform(Train_Y)\n",
    "Test_Y_e = Encoder.fit_transform(Test_Y)\n",
    "Val_Y_e = Encoder.fit_transform(Val_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d58f46-a1f0-47d1-a514-79a7335fef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9c14031f-b2b1-4d6d-91d1-0684ec6b210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(train_df['lemmatized'])\n",
    "\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "Val_X_Tfidf = Tfidf_vect.transform(Val_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c6990d-f1fb-4785-ad7f-85d5d117d0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "eed9a5c7-e0c8-417e-93fa-b38b2f8e1933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score: Training Data ->  100.0\n",
      "SVM Accuracy Score: Test Data ->  100.0\n",
      "SVM Accuracy Score: Validation Data ->  37.083333333333336\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC()\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)# predict the labels on validation dataset\n",
    "\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)# Use accuracy_score function to get the accuracy\n",
    "predictions_SVM_train = SVM.predict(Train_X_Tfidf)# Use accuracy_score function to get the accuracy\n",
    "predictions_SVM_val = SVM.predict(Val_X_Tfidf)# Use accuracy_score function to get the accuracy\n",
    "\n",
    "\n",
    "print(\"SVM Accuracy Score: Training Data -> \",accuracy_score(predictions_SVM_train, Train_Y)*100)\n",
    "print(\"SVM Accuracy Score: Test Data -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
    "print(\"SVM Accuracy Score: Validation Data -> \",accuracy_score(predictions_SVM_val, Val_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c84a4f4c-3f78-42a4-8234-629c651f9ad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "                                          precision    recall  f1-score   support\n",
      "\n",
      "                             A. L. O. E.       1.00      1.00      1.00         3\n",
      "                         Aimard, Gustave       1.00      1.00      1.00         3\n",
      "                     Alger, Horatio, Jr.       1.00      1.00      1.00         3\n",
      "                       Balzac, Honoré de       1.00      1.00      1.00         3\n",
      "                    Barbour, Ralph Henry       1.00      1.00      1.00         3\n",
      "               Baring-Gould, S. (Sabine)       1.00      1.00      1.00         3\n",
      "            Baum, L. Frank (Lyman Frank)       1.00      1.00      1.00         3\n",
      "                         Belloc, Hilaire       1.00      1.00      1.00         3\n",
      "                         Bennett, Arnold       1.00      1.00      1.00         3\n",
      "         Benson, E. F. (Edward Frederic)       1.00      1.00      1.00         3\n",
      "                     Blanchard, Amy Ella       1.00      1.00      1.00         3\n",
      "                         Bond, Nelson S.       1.00      1.00      1.00         3\n",
      "                            Bower, B. M.       1.00      1.00      1.00         3\n",
      "         Braddon, M. E. (Mary Elizabeth)       1.00      1.00      1.00         3\n",
      "                   Burroughs, Edgar Rice       1.00      1.00      1.00         3\n",
      "                         Cannon, Richard       1.00      1.00      1.00         3\n",
      "           Carter, Nicholas (House name)       1.00      1.00      1.00         3\n",
      "                        Castlemon, Harry       1.00      1.00      1.00         3\n",
      "       Chesterton, G. K. (Gilbert Keith)       1.00      1.00      1.00         3\n",
      "                          Conrad, Joseph       1.00      1.00      1.00         3\n",
      "                  Davis, Richard Harding       1.00      1.00      1.00         3\n",
      "                        Dickens, Charles       1.00      1.00      1.00         3\n",
      "                     Doyle, Arthur Conan       1.00      1.00      1.00         3\n",
      "                        Dumas, Alexandre       1.00      1.00      1.00         3\n",
      "                 Ellis, Edward Sylvester       1.00      1.00      1.00         3\n",
      "                     Garis, Howard Roger       1.00      1.00      1.00         3\n",
      "                        Garrett, Randall       1.00      1.00      1.00         3\n",
      "                    Goldfrap, John Henry       1.00      1.00      1.00         3\n",
      "                            Grant, James       1.00      1.00      1.00         3\n",
      "         Haggard, H. Rider (Henry Rider)       1.00      1.00      1.00         3\n",
      "      Hancock, H. Irving (Harrie Irving)       1.00      1.00      1.00         3\n",
      "     Harper, Charles G. (Charles George)       1.00      1.00      1.00         3\n",
      "                             Harte, Bret       1.00      1.00      1.00         3\n",
      "                    Hawthorne, Nathaniel       1.00      1.00      1.00         3\n",
      "            Henty, G. A. (George Alfred)       1.00      1.00      1.00         3\n",
      "                           Hoare, Edward       1.00      1.00      1.00         3\n",
      "                       Holmes, Mary Jane       1.00      1.00      1.00         3\n",
      "                   Howells, William Dean       1.00      1.00      1.00         3\n",
      "                            Hume, Fergus       1.00      1.00      1.00         3\n",
      "          Jacobs, W. W. (William Wymark)       1.00      1.00      1.00         3\n",
      "James, G. P. R. (George Payne Rainsford)       1.00      1.00      1.00         3\n",
      "                            James, Henry       1.00      1.00      1.00         3\n",
      "                        Kipling, Rudyard       1.00      1.00      1.00         3\n",
      "                            Lang, Andrew       1.00      1.00      1.00         3\n",
      "                       Le Queux, William       1.00      1.00      1.00         3\n",
      "                        Leinster, Murray       1.00      1.00      1.00         3\n",
      "                    Lever, Charles James       1.00      1.00      1.00         3\n",
      "   Library of Congress. Copyright Office       1.00      1.00      1.00         3\n",
      "                            London, Jack       1.00      1.00      1.00         3\n",
      "     Lytton, Edward Bulwer Lytton, Baron       1.00      1.00      1.00         3\n",
      "                       MacDonald, George       1.00      1.00      1.00         3\n",
      "                        Marlowe, Stephen       1.00      1.00      1.00         3\n",
      "                    Matthews, Stanley R.       1.00      1.00      1.00         3\n",
      "                            Meade, L. T.       1.00      1.00      1.00         3\n",
      "                        Meredith, George       1.00      1.00      1.00         3\n",
      "             Miller, Alex. McVeigh, Mrs.       1.00      1.00      1.00         3\n",
      "               Oliphant, Mrs. (Margaret)       1.00      1.00      1.00         3\n",
      "                         Parker, Gilbert       1.00      1.00      1.00         3\n",
      "                     Roosevelt, Theodore       1.00      1.00      1.00         3\n",
      "                  Russell, William Clark       1.00      1.00      1.00         3\n",
      "                           Scott, Walter       1.00      1.00      1.00         3\n",
      "                    Shakespeare, William       1.00      1.00      1.00         3\n",
      "                         Sinclair, Upton       1.00      1.00      1.00         3\n",
      "        Smith, George O. (George Oliver)       1.00      1.00      1.00         3\n",
      "              Snell, Roy J. (Roy Judson)       1.00      1.00      1.00         3\n",
      "                       Standish, Burt L.       1.00      1.00      1.00         3\n",
      "                 Stevenson, Robert Louis       1.00      1.00      1.00         3\n",
      "                     Stratemeyer, Edward       1.00      1.00      1.00         3\n",
      "                      Tolstoy, Leo, graf       1.00      1.00      1.00         3\n",
      "                       Trollope, Anthony       1.00      1.00      1.00         3\n",
      "               Tuttle, W. C. (Wilbur C.)       1.00      1.00      1.00         3\n",
      "                             Twain, Mark       1.00      1.00      1.00         3\n",
      "    United States. National Park Service       1.00      1.00      1.00         3\n",
      "                            Verne, Jules       1.00      1.00      1.00         3\n",
      "                          Wells, Carolyn       1.00      1.00      1.00         3\n",
      "           Wells, H. G. (Herbert George)       1.00      1.00      1.00         3\n",
      "     Westerman, Percy F. (Percy Francis)       1.00      1.00      1.00         3\n",
      "                          Wharton, Edith       1.00      1.00      1.00         3\n",
      "    Yonge, Charlotte M. (Charlotte Mary)       1.00      1.00      1.00         3\n",
      "                             Zola, Émile       1.00      1.00      1.00         3\n",
      "\n",
      "                                accuracy                           1.00       240\n",
      "                               macro avg       1.00      1.00      1.00       240\n",
      "                            weighted avg       1.00      1.00      1.00       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(\"Classification Report:\\n\")\n",
    "train_class_rpt = classification_report(Train_Y, predictions_SVM_train)\n",
    "print(train_class_rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd45765-93e8-4dba-84ef-aa892e2c9ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72e6e5-e908-4e19-8165-2e153e2e2fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "63d3bd29-105f-4a4b-93fa-80f3a4444687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Classification Report:\n",
      "\n",
      "                                          precision    recall  f1-score   support\n",
      "\n",
      "                             A. L. O. E.       0.00      0.00      0.00         3\n",
      "                         Aimard, Gustave       1.00      0.67      0.80         3\n",
      "                     Alger, Horatio, Jr.       0.00      0.00      0.00         3\n",
      "                       Balzac, Honoré de       1.00      0.33      0.50         3\n",
      "                    Barbour, Ralph Henry       0.50      0.33      0.40         3\n",
      "               Baring-Gould, S. (Sabine)       0.25      0.33      0.29         3\n",
      "            Baum, L. Frank (Lyman Frank)       0.00      0.00      0.00         3\n",
      "                         Belloc, Hilaire       0.00      0.00      0.00         3\n",
      "                         Bennett, Arnold       0.00      0.00      0.00         3\n",
      "         Benson, E. F. (Edward Frederic)       0.50      0.33      0.40         3\n",
      "                     Blanchard, Amy Ella       0.00      0.00      0.00         3\n",
      "                         Bond, Nelson S.       0.33      0.33      0.33         3\n",
      "                            Bower, B. M.       0.50      0.33      0.40         3\n",
      "         Braddon, M. E. (Mary Elizabeth)       0.00      0.00      0.00         3\n",
      "                   Burroughs, Edgar Rice       0.00      0.00      0.00         3\n",
      "                         Cannon, Richard       1.00      1.00      1.00         3\n",
      "           Carter, Nicholas (House name)       1.00      1.00      1.00         3\n",
      "                        Castlemon, Harry       0.00      0.00      0.00         3\n",
      "       Chesterton, G. K. (Gilbert Keith)       0.50      0.33      0.40         3\n",
      "                          Conrad, Joseph       0.17      0.33      0.22         3\n",
      "                  Davis, Richard Harding       0.00      0.00      0.00         3\n",
      "                        Dickens, Charles       0.33      0.33      0.33         3\n",
      "                     Doyle, Arthur Conan       0.50      0.33      0.40         3\n",
      "                        Dumas, Alexandre       1.00      0.33      0.50         3\n",
      "                 Ellis, Edward Sylvester       0.50      0.67      0.57         3\n",
      "                     Garis, Howard Roger       1.00      0.67      0.80         3\n",
      "                        Garrett, Randall       0.00      0.00      0.00         3\n",
      "                    Goldfrap, John Henry       0.50      0.33      0.40         3\n",
      "                            Grant, James       0.50      0.33      0.40         3\n",
      "         Haggard, H. Rider (Henry Rider)       1.00      0.33      0.50         3\n",
      "      Hancock, H. Irving (Harrie Irving)       1.00      0.67      0.80         3\n",
      "     Harper, Charles G. (Charles George)       0.33      0.33      0.33         3\n",
      "                             Harte, Bret       0.00      0.00      0.00         3\n",
      "                    Hawthorne, Nathaniel       1.00      0.33      0.50         3\n",
      "            Henty, G. A. (George Alfred)       0.75      1.00      0.86         3\n",
      "                           Hoare, Edward       0.75      1.00      0.86         3\n",
      "                       Holmes, Mary Jane       0.33      0.33      0.33         3\n",
      "                   Howells, William Dean       0.21      1.00      0.35         3\n",
      "                            Hume, Fergus       0.00      0.00      0.00         3\n",
      "          Jacobs, W. W. (William Wymark)       0.75      1.00      0.86         3\n",
      "James, G. P. R. (George Payne Rainsford)       0.00      0.00      0.00         3\n",
      "                            James, Henry       0.40      0.67      0.50         3\n",
      "                        Kipling, Rudyard       0.25      0.33      0.29         3\n",
      "                            Lang, Andrew       0.00      0.00      0.00         3\n",
      "                       Le Queux, William       1.00      0.67      0.80         3\n",
      "                        Leinster, Murray       0.00      0.00      0.00         3\n",
      "                    Lever, Charles James       0.21      1.00      0.35         3\n",
      "   Library of Congress. Copyright Office       1.00      0.67      0.80         3\n",
      "                            London, Jack       0.50      0.33      0.40         3\n",
      "     Lytton, Edward Bulwer Lytton, Baron       0.00      0.00      0.00         3\n",
      "                       MacDonald, George       0.06      0.33      0.11         3\n",
      "                        Marlowe, Stephen       0.00      0.00      0.00         3\n",
      "                    Matthews, Stanley R.       1.00      1.00      1.00         3\n",
      "                            Meade, L. T.       0.00      0.00      0.00         3\n",
      "                        Meredith, George       0.00      0.00      0.00         3\n",
      "             Miller, Alex. McVeigh, Mrs.       1.00      0.67      0.80         3\n",
      "               Oliphant, Mrs. (Margaret)       0.00      0.00      0.00         3\n",
      "                         Parker, Gilbert       0.00      0.00      0.00         3\n",
      "                     Roosevelt, Theodore       0.50      1.00      0.67         3\n",
      "                  Russell, William Clark       0.75      1.00      0.86         3\n",
      "                           Scott, Walter       0.75      1.00      0.86         3\n",
      "                    Shakespeare, William       1.00      1.00      1.00         3\n",
      "                         Sinclair, Upton       1.00      0.33      0.50         3\n",
      "        Smith, George O. (George Oliver)       1.00      0.33      0.50         3\n",
      "              Snell, Roy J. (Roy Judson)       0.25      0.33      0.29         3\n",
      "                       Standish, Burt L.       1.00      1.00      1.00         3\n",
      "                 Stevenson, Robert Louis       0.04      0.33      0.07         3\n",
      "                     Stratemeyer, Edward       0.33      0.33      0.33         3\n",
      "                      Tolstoy, Leo, graf       0.00      0.00      0.00         3\n",
      "                       Trollope, Anthony       0.00      0.00      0.00         3\n",
      "               Tuttle, W. C. (Wilbur C.)       1.00      0.67      0.80         3\n",
      "                             Twain, Mark       0.33      0.33      0.33         3\n",
      "    United States. National Park Service       1.00      0.33      0.50         3\n",
      "                            Verne, Jules       0.00      0.00      0.00         3\n",
      "                          Wells, Carolyn       0.00      0.00      0.00         3\n",
      "           Wells, H. G. (Herbert George)       0.25      0.33      0.29         3\n",
      "     Westerman, Percy F. (Percy Francis)       0.67      0.67      0.67         3\n",
      "                          Wharton, Edith       0.00      0.00      0.00         3\n",
      "    Yonge, Charlotte M. (Charlotte Mary)       0.00      0.00      0.00         3\n",
      "                             Zola, Émile       0.33      0.67      0.44         3\n",
      "\n",
      "                                accuracy                           0.37       240\n",
      "                               macro avg       0.41      0.37      0.36       240\n",
      "                            weighted avg       0.41      0.37      0.36       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dean/anaconda3/envs/school-env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dean/anaconda3/envs/school-env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dean/anaconda3/envs/school-env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Validation Classification Report:\\n\")\n",
    "test_class_rpt = classification_report(Val_Y, predictions_SVM_val)\n",
    "print(test_class_rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e27d933-913a-4cc6-b1c2-3f2bd4f045f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_school_env",
   "language": "python",
   "name": "school_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
